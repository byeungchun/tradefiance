"""Convert IMF DOT series to DBnomics format.

Usage:
    {self_filename} <source_dir> <target_dir> [options]

source_dir: path of source directory containing BIS series generated by download.py script
target_dir: path of target directory to write datasets & series in DBnomics format
            => all files will be deleted

Options:
    --debug                                     show debug output
    --only <datasets_codes_or_filenames>        only convert given dataset_code or filenames
                                                (ex: "--only CBS,DSRP", "--only full_WEBSTATS_DSR_DATAFLOW_csv.csv")
"""

import os
import re
import sys
import logging
import ujson as json
from docopt import docopt
from collections import defaultdict
from toolz import merge


DATASET_CODES_AND_NAMES = {
  'DOT_timeSeries.csv': ('DOT', 'directions of trade statistics'),
}

JSONL_DATASETS = ['DOT']

log = logging.getLogger(__name__)
NOT_AVAILABLE = 'NA'

def main():
  global log
  global args

  # Parse command line arguments
  args = docopt(__doc__.format(self_filename=os.path.basename(__file__)))
  source_dir = args['<source_dir>']
  assert os.path.exists(source_dir)
  target_dir = args['<target_dir>']
  debug_mode = args['--debug']
  logging.basicConfig(level=(logging.DEBUG if debug_mode else logging.INFO), format='%(message)s')

  categories_tree = []

  for csv_filename in [f for f in os.listdir(source_dir) if f.endswith('.csv')]:
    csv_filepath = os.path.join(source_dir, csv_filename)
    dot_parser = parse_dot_file(csv_filepath)
    dataset_json = next(dot_parser)
    dataset_code = dataset_json['code']
    log.info("-> {}".format(dataset_code))
    dataset_path = os.path.join(target_dir, dataset_code)
    os.mkdir(dataset_path)

    use_jsonl_for_series_info = dataset_code in JSONL_DATASETS
    if use_jsonl_for_series_info:
      series_jsonl_file = open(os.path.join(dataset_path, 'series_jsonl'),'w')
      dataset_json['series'] = {'path': 'series.jsonl'}
    else:
      dataset_json['series'] = []
    dimensions_values_labels = defaultdict(dict)

    for series_dict in dot_parser:
      series_code = series_dict['code']
      series_code = series_code.replace(':','.')
      series_json_info = {
        'code': series_code,
        'dimensions': series_dict['dimensions'],
      }
      if use_jsonl_for_series_info:
        series_jsonl_file.write(json.dumps(series_json_info, sort_keys=True)+"\n")
      else:
        dataset_json['series'].append(series_json_info)
      with open(os.path.join(dataset_path,series_code+'.tsv'), 'w', encoding='utf-8') as observations_file:
        observations_file.write("PERIOD\tVALUE\n")
        for observation in series_dict['observations']:
          observations_file.write("\t".join(observation)+ "\n")
      for dimension_label, values_labels in series_dict['dimensions_values_labels'].items():
        dimensions_values_labels[dimension_label] = merge(dimensions_values_labels[dimension_label], values_labels)
    
    if use_jsonl_for_series_info:
      series_jsonl_file.close()

    dataset_json['dimensions_values_labels'] = dimensions_values_labels
    write_json_file(os.path.join(dataset_path, 'dataset.json'), dataset_json)

    categories_tree.append({
      "code": dataset_code,
      "name": dataset_json["name"]
    })

    log.info("")
  
  write_json_file(os.path.join(target_dir, 'category_tree.json'), categories_tree)

  log.info("\nEND")

def parse_dot_file(dotfile):
  is_metadata = True
  dot_regexp = re.compile('(?:^|,)(?=[^"]|(")?)"?((?(1)[^"]*|[^,"]*))"?(?=,|$)')
  with open(dotfile, encoding='utf-8-sig') as dot_file:
    while True:
      line = dot_file.readline().strip()
      if line == '':
        break
      line = line[:-1] if len(line) > 0 and line[-1] == ',' else line
      
      elements = list(map(lambda x: x[1].strip(), dot_regexp.findall(line)))
      if is_metadata:
        assert 'Attribute' in elements
        nb_dimensions = elements.index('Attribute')
        dimensions_labels = [
          cell
          for cell_idx, cell in enumerate(elements[:nb_dimensions])
          if cell_idx % 2 == 0
        ]
        dimensions_codes = [
          cell
          for cell_idx, cell in enumerate(elements[:nb_dimensions])
          if cell_idx % 2 == 1
        ]
        time_periods_labels = elements[nb_dimensions+1:]
        yield {
          'code':'DOT',
          'name':'Directions of Trade',
          'dimensions_codes_order': dimensions_codes,
          'dimensions_labels': dict(zip(dimensions_codes, dimensions_labels)),
        }
        is_metadata = False
      else:
        if elements[nb_dimensions] == 'Status':
          continue # This line is not values but obs status. <- Need code for treatment
        line_dimensions_values_labels = [
          cell
          for cell_idx, cell in enumerate(elements[:nb_dimensions])
          if cell_idx % 2 == 0
        ]
        line_dimensions_values_codes = [
          cell
          for cell_idx, cell in enumerate(elements[:nb_dimensions])
          if cell_idx % 2 == 1
        ]
        dimensions = (dict(zip(dimensions_codes, line_dimensions_values_codes)))
        dimensions_values_labels = {
          dimension_code: {
            line_dimensions_values_codes[dimension_code_index]: line_dimensions_values_labels[dimension_code_index]
          }
          for dimension_code_index, dimension_code in enumerate(dimensions_codes)

        }
        observations = [
          (period, value)
          for period, value in zip(time_periods_labels, elements[nb_dimensions+1:]) if value != ''
        ]

        # Sort frequency 
        if all(len(x[0]) == 4 for x in observations): # Annual
          line_dimensions_values_codes = ['A'] + line_dimensions_values_codes
        elif all('Q' in x[0] for x in observations): # Quarterly
          line_dimensions_values_codes = ['Q'] + line_dimensions_values_codes
        elif all('M' in x[0] for x in observations): # Monthly
          line_dimensions_values_codes = ['M'] + line_dimensions_values_codes
        else:
          log.error('multiple frequencies in one row -> {}'.format('.'.join(line_dimensions_values_codes)))
          sys.exit(-1)


        yield {
          'code': '.'.join(line_dimensions_values_codes),
          'dimensions': dimensions,
          'dimensions_values_labels': dimensions_values_labels,
          'observations': observations,
        }

def write_json_file(file_path, data):
  with open(file_path, 'w', encoding='utf-8') as file_:
    json.dump(data, file_, ensure_ascii=False, indent=2, sort_keys=True)

if __name__ == '__main__':
  sys.exit(main())